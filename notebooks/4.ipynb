{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0bf9d23f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from torch.utils.data import DataLoader, TensorDataset, Dataset\n",
    "import yfinance as yf\n",
    "import warnings\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "76ca2567",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TimeSeriesDataset(Dataset):\n",
    "    def __init__(self, X, y):\n",
    "        self.X = torch.tensor(X, dtype=torch.float32)\n",
    "        self.y = torch.tensor(y, dtype=torch.float32)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.X)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.X[idx], self.y[idx]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "97ad0597",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LSTMModel(nn.Module):\n",
    "    def __init__(self, input_size=1, hidden_size=50, num_layers=2, output_size=1):\n",
    "        super().__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.num_layers = num_layers\n",
    "        \n",
    "        self.lstm = nn.LSTM(\n",
    "            input_size, hidden_size, num_layers,\n",
    "            batch_first=True, dropout=0.2\n",
    "        )\n",
    "        self.dropout = nn.Dropout(0.2)\n",
    "        self.fc = nn.Linear(hidden_size, output_size)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        device = x.device\n",
    "\n",
    "        h0 = torch.zeros(self.num_layers, x.size(0), self.hidden_size, device=device)\n",
    "        c0 = torch.zeros(self.num_layers, x.size(0), self.hidden_size, device=device)\n",
    "        \n",
    "        out, _ = self.lstm(x, (h0, c0))\n",
    "        out = self.dropout(out[:, -1, :])\n",
    "        out = self.fc(out)\n",
    "        return out\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "3ef7c7ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Attention(nn.Module):\n",
    "    def __init__(self, hidden_dim):\n",
    "        super().__init__()\n",
    "        self.attn = nn.Linear(hidden_dim, 1)\n",
    "\n",
    "    def forward(self, lstm_out):\n",
    "        weights = torch.softmax(self.attn(lstm_out), dim=1)\n",
    "        context = torch.sum(weights * lstm_out, dim=1)\n",
    "        return context\n",
    "\n",
    "\n",
    "class CNN_BiLSTM_Attention(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, cnn_out=32, kernel=3):\n",
    "        super().__init__()\n",
    "\n",
    "        self.conv = nn.Conv1d(input_size, cnn_out, kernel, padding=kernel // 2)\n",
    "        self.bn = nn.BatchNorm1d(cnn_out)\n",
    "        self.relu = nn.ReLU()\n",
    "\n",
    "        self.lstm = nn.LSTM(\n",
    "            input_size=cnn_out,\n",
    "            hidden_size=hidden_size,\n",
    "            batch_first=True,\n",
    "            bidirectional=True\n",
    "        )\n",
    "\n",
    "        self.attention = Attention(hidden_dim=hidden_size * 2)\n",
    "        self.fc = nn.Linear(hidden_size * 2, 1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x.permute(0, 2, 1)           # (batch, features, seq)\n",
    "        x = self.relu(self.bn(self.conv(x)))\n",
    "        x = x.permute(0, 2, 1)\n",
    "\n",
    "        lstm_out, _ = self.lstm(x)\n",
    "        context = self.attention(lstm_out)\n",
    "        output = self.fc(context)\n",
    "        return output\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "5dac50c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_yf_dataframe(df):\n",
    "    df = df.copy()\n",
    "    \n",
    "    if isinstance(df.columns, pd.MultiIndex):\n",
    "        df.columns.names = ['DataType', 'Ticker']\n",
    "        df = df.stack(level=1).reset_index()\n",
    "        df = df.rename(columns={'level_1': 'Ticker'})\n",
    "    else:\n",
    "        df = df.reset_index()\n",
    "        df['Ticker'] = df.columns[1].split()[0] if ' ' in df.columns[1] else 'UNKNOWN'\n",
    "\n",
    "    df = df.rename(columns=str.capitalize)\n",
    "    cols = ['Date', 'Ticker', 'Open', 'High', 'Low', 'Close', 'Volume']\n",
    "    df = df[[c for c in cols if c in df.columns]]\n",
    "\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "38332675",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_sliding_window(data, feature_cols, target_col, window_size=60):\n",
    "    X, y = [], []\n",
    "    values = data[feature_cols].values\n",
    "    targets = data[target_col].values\n",
    "\n",
    "    if len(data) <= window_size:\n",
    "        raise ValueError(f\"Недостаточно данных для построения sliding window: \"\n",
    "                         f\"len(data)={len(data)}, window_size={window_size}\")\n",
    "\n",
    "    for i in range(window_size, len(data)):\n",
    "        X.append(values[i - window_size:i])\n",
    "        y.append(targets[i])\n",
    "    \n",
    "    return np.array(X), np.array(y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "10c21960",
   "metadata": {},
   "outputs": [],
   "source": [
    "def scale(data, scaler):\n",
    "    csale_d = data.reshape(-1, data.shape[2])\n",
    "    csale_d = scaler.transform(csale_d)\n",
    "    return csale_d.reshape(data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "9be22bf3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_data(df, seq_len, shift):\n",
    "    df = normalize_yf_dataframe(df)\n",
    "\n",
    "    if 'Date' in df.columns:\n",
    "        df['Date'] = pd.to_datetime(df['Date'])\n",
    "\n",
    "    target_col = f\"Next_Close_t{shift}\"\n",
    "    df[target_col] = df[\"Close\"].shift(-shift)\n",
    "    df = df.dropna().reset_index(drop=True)\n",
    "\n",
    "    features = [\"Open\", \"High\", \"Low\", \"Close\", \"Volume\"]\n",
    "    features = [ \"Close\"]\n",
    "\n",
    "    # ==== масштабування до sliding window ====\n",
    "    X_raw = df[features].values           # (N, 5)\n",
    "    y_raw = df[[target_col]].values       # (N, 1)\n",
    "\n",
    "    scaler_x = StandardScaler().fit(X_raw)\n",
    "    scaler_y = StandardScaler().fit(y_raw)\n",
    "\n",
    "    df_scaled = df.copy()\n",
    "    df_scaled[features] = scaler_x.transform(X_raw)\n",
    "    df_scaled[target_col] = scaler_y.transform(y_raw)\n",
    "\n",
    "    # ==== sliding window ====\n",
    "    X, y = make_sliding_window(df_scaled, features, target_col, window_size=seq_len)\n",
    "\n",
    "    # ==== split ====\n",
    "    train_size = int(len(X) * 0.7)\n",
    "    val_size = int(len(X) * 0.15)\n",
    "\n",
    "    X_train = X[:train_size]\n",
    "    y_train = y[:train_size]\n",
    "\n",
    "    X_val = X[train_size:train_size + val_size]\n",
    "    y_val = y[train_size:train_size + val_size]\n",
    "\n",
    "    X_test = X[train_size + val_size:]\n",
    "    y_test = y[train_size + val_size:]\n",
    "\n",
    "    # ==== torch loaders ====\n",
    "    train_loader = DataLoader(\n",
    "        TimeSeriesDataset(X_train, y_train),\n",
    "        batch_size=32, shuffle=True\n",
    "    )\n",
    "\n",
    "    val_loader = DataLoader(\n",
    "        TimeSeriesDataset(X_val, y_val),\n",
    "        batch_size=32, shuffle=False\n",
    "    )\n",
    "\n",
    "    return (\n",
    "        train_loader,\n",
    "        val_loader,\n",
    "        X_test,\n",
    "        y_test,\n",
    "        scaler_x,\n",
    "        scaler_y,\n",
    "        df_scaled\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "364b421d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, loader, val_loader, optimizer, loss_fn, device, epochs=30):\n",
    "    # scheduler снижает LR, если val_loss перестал улучшаться\n",
    "    scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(\n",
    "        optimizer,\n",
    "        mode='min',\n",
    "        factor=0.5,\n",
    "        patience=3\n",
    "    )\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        model.train()\n",
    "        losses = []\n",
    "\n",
    "        for Xb, yb in loader:\n",
    "            Xb, yb = Xb.to(device), yb.to(device)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            pred = model(Xb).flatten()\n",
    "\n",
    "            loss = loss_fn(pred, yb)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            losses.append(loss.item())\n",
    "\n",
    "        # validation\n",
    "        model.eval()\n",
    "        val_losses = []\n",
    "        with torch.no_grad():\n",
    "            for Xb, yb in val_loader:\n",
    "                Xb, yb = Xb.to(device), yb.to(device)\n",
    "                pred = model(Xb).flatten()\n",
    "                val_losses.append(loss_fn(pred, yb).item())\n",
    "\n",
    "        train_loss = np.mean(losses)\n",
    "        val_loss = np.mean(val_losses)\n",
    "\n",
    "        # шаг шедулера\n",
    "        scheduler.step(val_loss)\n",
    "\n",
    "        print(\n",
    "            f\"Epoch {epoch+1}/{epochs} | \"\n",
    "            f\"Train Loss={train_loss:.4f} | \"\n",
    "            f\"Val Loss={val_loss:.4f} | \"\n",
    "            f\"LR={optimizer.param_groups[0]['lr']:.6f}\"\n",
    "        )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "f36f9fda",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(model, X, y_true_scaled, scaler_y, device):\n",
    "    model.eval()\n",
    "    X = torch.tensor(X, dtype=torch.float32).to(device)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        preds = model(X).cpu().numpy().flatten()\n",
    "\n",
    "    # вернуть масштаб\n",
    "    preds_real = scaler_y.inverse_transform(preds.reshape(-1, 1)).flatten()\n",
    "    y_real = scaler_y.inverse_transform(y_true_scaled.reshape(-1, 1)).flatten()\n",
    "\n",
    "    mae = mean_absolute_error(y_real, preds_real)\n",
    "    rmse = mean_squared_error(y_real, preds_real) ** 0.5\n",
    "    mape = np.mean(np.abs((y_real - preds_real) / y_real)) * 100\n",
    "    r2 = r2_score(y_real, preds_real)\n",
    "\n",
    "    print(\"\\n=== METRICS ===\")\n",
    "    print(f\"MAE:  {mae:.4f}\")\n",
    "    print(f\"RMSE: {rmse:.4f}\")\n",
    "    print(f\"MAPE: {mape:.2f}%\")\n",
    "    print(f\"R²:   {r2:.4f}\")\n",
    "\n",
    "    return preds_real, y_real"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "813200dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pipeline(df, seq_len, shift, epochs):\n",
    "    train_loader, val_loader, X_test, y_test_sc, scaler_x, scaler_y,df = prepare_data(df, seq_len, shift)\n",
    "\n",
    "    device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "    # device =\"cpu\"\n",
    "    print(\"Using device:\", device)\n",
    "\n",
    "    model = CNN_BiLSTM_Attention(input_size=X_test.shape[2], hidden_size=64).to(device)\n",
    "    model = LSTMModel(input_size=X_test.shape[2], hidden_size=64)\n",
    "\n",
    "    loss_fn = nn.MSELoss()\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)\n",
    "    model = model.to(device)\n",
    "\n",
    "    train(model, train_loader, val_loader, optimizer, loss_fn, device, epochs)\n",
    "    preds, y_real = evaluate(model, X_test, y_test_sc, scaler_y, device)\n",
    "\n",
    "    return model, scaler_x, scaler_y, optimizer\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "fbd031c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[*********************100%***********************]  1 of 1 completed\n"
     ]
    }
   ],
   "source": [
    "ticker = \"MSFT\"\n",
    "\n",
    "df = yf.download(ticker, period=\"2y\", interval=\"1h\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a4162082",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[*********************100%***********************]  1 of 1 completed\n"
     ]
    }
   ],
   "source": [
    "\n",
    "df = yf.download( \"BTC-USD\", period=\"2y\", interval=\"1h\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "1fe5c39b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr:last-of-type th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th>Price</th>\n",
       "      <th>Close</th>\n",
       "      <th>High</th>\n",
       "      <th>Low</th>\n",
       "      <th>Open</th>\n",
       "      <th>Volume</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Ticker</th>\n",
       "      <th>BTC-USD</th>\n",
       "      <th>BTC-USD</th>\n",
       "      <th>BTC-USD</th>\n",
       "      <th>BTC-USD</th>\n",
       "      <th>BTC-USD</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Datetime</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2023-11-21 19:00:00+02:00</th>\n",
       "      <td>36947.367188</td>\n",
       "      <td>37504.339844</td>\n",
       "      <td>36761.171875</td>\n",
       "      <td>37189.367188</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-11-21 20:00:00+02:00</th>\n",
       "      <td>36906.851562</td>\n",
       "      <td>36974.835938</td>\n",
       "      <td>36747.679688</td>\n",
       "      <td>36917.785156</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-11-21 21:00:00+02:00</th>\n",
       "      <td>36991.433594</td>\n",
       "      <td>37109.394531</td>\n",
       "      <td>36779.968750</td>\n",
       "      <td>36901.960938</td>\n",
       "      <td>61929472</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-11-21 22:00:00+02:00</th>\n",
       "      <td>36963.566406</td>\n",
       "      <td>37167.101562</td>\n",
       "      <td>36866.132812</td>\n",
       "      <td>36983.945312</td>\n",
       "      <td>442103808</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-11-21 23:00:00+02:00</th>\n",
       "      <td>36815.226562</td>\n",
       "      <td>37025.535156</td>\n",
       "      <td>36750.574219</td>\n",
       "      <td>36938.578125</td>\n",
       "      <td>82348032</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2025-11-21 14:00:00+02:00</th>\n",
       "      <td>83142.976562</td>\n",
       "      <td>83471.179688</td>\n",
       "      <td>80756.515625</td>\n",
       "      <td>82217.890625</td>\n",
       "      <td>8844345344</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2025-11-21 15:00:00+02:00</th>\n",
       "      <td>84121.773438</td>\n",
       "      <td>84270.007812</td>\n",
       "      <td>83142.187500</td>\n",
       "      <td>83152.867188</td>\n",
       "      <td>2319384576</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2025-11-21 16:00:00+02:00</th>\n",
       "      <td>85038.867188</td>\n",
       "      <td>85339.585938</td>\n",
       "      <td>83507.343750</td>\n",
       "      <td>84035.828125</td>\n",
       "      <td>8462057472</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2025-11-21 17:00:00+02:00</th>\n",
       "      <td>82816.710938</td>\n",
       "      <td>84938.171875</td>\n",
       "      <td>82808.132812</td>\n",
       "      <td>84938.171875</td>\n",
       "      <td>52669784064</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2025-11-21 18:00:00+02:00</th>\n",
       "      <td>84462.906250</td>\n",
       "      <td>84462.906250</td>\n",
       "      <td>82414.476562</td>\n",
       "      <td>82922.843750</td>\n",
       "      <td>41762373632</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>17443 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "Price                             Close          High           Low  \\\n",
       "Ticker                          BTC-USD       BTC-USD       BTC-USD   \n",
       "Datetime                                                              \n",
       "2023-11-21 19:00:00+02:00  36947.367188  37504.339844  36761.171875   \n",
       "2023-11-21 20:00:00+02:00  36906.851562  36974.835938  36747.679688   \n",
       "2023-11-21 21:00:00+02:00  36991.433594  37109.394531  36779.968750   \n",
       "2023-11-21 22:00:00+02:00  36963.566406  37167.101562  36866.132812   \n",
       "2023-11-21 23:00:00+02:00  36815.226562  37025.535156  36750.574219   \n",
       "...                                 ...           ...           ...   \n",
       "2025-11-21 14:00:00+02:00  83142.976562  83471.179688  80756.515625   \n",
       "2025-11-21 15:00:00+02:00  84121.773438  84270.007812  83142.187500   \n",
       "2025-11-21 16:00:00+02:00  85038.867188  85339.585938  83507.343750   \n",
       "2025-11-21 17:00:00+02:00  82816.710938  84938.171875  82808.132812   \n",
       "2025-11-21 18:00:00+02:00  84462.906250  84462.906250  82414.476562   \n",
       "\n",
       "Price                              Open       Volume  \n",
       "Ticker                          BTC-USD      BTC-USD  \n",
       "Datetime                                              \n",
       "2023-11-21 19:00:00+02:00  37189.367188            0  \n",
       "2023-11-21 20:00:00+02:00  36917.785156            0  \n",
       "2023-11-21 21:00:00+02:00  36901.960938     61929472  \n",
       "2023-11-21 22:00:00+02:00  36983.945312    442103808  \n",
       "2023-11-21 23:00:00+02:00  36938.578125     82348032  \n",
       "...                                 ...          ...  \n",
       "2025-11-21 14:00:00+02:00  82217.890625   8844345344  \n",
       "2025-11-21 15:00:00+02:00  83152.867188   2319384576  \n",
       "2025-11-21 16:00:00+02:00  84035.828125   8462057472  \n",
       "2025-11-21 17:00:00+02:00  84938.171875  52669784064  \n",
       "2025-11-21 18:00:00+02:00  82922.843750  41762373632  \n",
       "\n",
       "[17443 rows x 5 columns]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.index = df.index.tz_convert('Europe/Kiev')\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "a3c18644",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'pipeline' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[19]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m res = \u001b[43mpipeline\u001b[49m(df, \u001b[32m60\u001b[39m, \u001b[32m8\u001b[39m, \u001b[32m60\u001b[39m)\n",
      "\u001b[31mNameError\u001b[39m: name 'pipeline' is not defined"
     ]
    }
   ],
   "source": [
    "res = pipeline(df, 60, 8, 60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "228103e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_sequences(X, window):\n",
    "    X_seq = []\n",
    "    for i in range(len(X) - window):\n",
    "        X_seq.append(X[i:i+window])\n",
    "    return np.array(X_seq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "5cd7ce52",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_predictions(df, model, scaler_x, scaler_y, window, col_name, device):\n",
    "    model.eval()\n",
    "\n",
    "    features = [\"Close\"]\n",
    "    X_raw = df[features].values\n",
    "\n",
    "    X_all_scaled = scaler_x.transform(X_raw)\n",
    "\n",
    "    X_seq = []\n",
    "    for i in range(len(X_all_scaled) - window):\n",
    "        X_seq.append(X_all_scaled[i:i+window])\n",
    "    X_seq = np.array(X_seq)\n",
    "\n",
    "    X_tensor = torch.tensor(X_seq, dtype=torch.float32).to(device)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        y_pred_scaled = model(X_tensor).cpu().numpy().flatten()\n",
    "\n",
    "    y_pred_real = scaler_y.inverse_transform(y_pred_scaled.reshape(-1, 1)).flatten()\n",
    "\n",
    "    pred_column = np.full(len(df), np.nan)\n",
    "    start_index = window\n",
    "    pred_column[start_index:start_index + len(y_pred_real)] = y_pred_real\n",
    "\n",
    "    df[col_name] = pred_column\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "96c960d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import joblib \n",
    "import os\n",
    "\n",
    "\n",
    "def create_models(df: pd.DataFrame, shifts=(1, 3, 8), path_dir=None):\n",
    "    save_dir = 'models'\n",
    "    df_new = df.copy()\n",
    "    os.makedirs(save_dir, exist_ok=True)\n",
    "    if path_dir:\n",
    "        save_dir = f'models/{save_dir}'\n",
    "        os.makedirs(save_dir, exist_ok=True)\n",
    "\n",
    "\n",
    "    for shift in shifts:\n",
    "        path = f'predict_t{shift}'\n",
    "        os.makedirs(os.path.join(save_dir, path), exist_ok=True)\n",
    "\n",
    "        model, scaler_x, scaler_y, optimizer = pipeline(df, 60, shift, 60)\n",
    "\n",
    "        model_path = os.path.join(save_dir, path, \"model.pth\")\n",
    "        scaler_x_path = os.path.join(save_dir, path, \"scaler_x.pkl\")\n",
    "        scaler_y_path = os.path.join(save_dir, path, \"scaler_y.pkl\")\n",
    "\n",
    "        torch.save({\n",
    "            \"model_state_dict\": model.state_dict(),\n",
    "            \"optimizer_state_dict\": optimizer.state_dict()\n",
    "        }, model_path)\n",
    "\n",
    "        joblib.dump(scaler_x, scaler_x_path)\n",
    "        joblib.dump(scaler_y, scaler_y_path)\n",
    "\n",
    "        df_new = make_predictions(df_new, model, scaler_x, scaler_y, 60, path, 'cuda')\n",
    "\n",
    "        print(f\"✅ Модель t={shift} сохранена и предсказания добавлены\")\n",
    "\n",
    "    df_new.to_csv(os.path.join(save_dir, 'new_data.csv'), index=False)\n",
    "    print(\"✅ Все модели обучены и результаты сохранены в new_data.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "eeb6ab19",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n",
      "Epoch 1/60 | Train Loss=0.0389 | Val Loss=0.0186 | LR=0.001000\n",
      "Epoch 2/60 | Train Loss=0.0063 | Val Loss=0.0259 | LR=0.001000\n",
      "Epoch 3/60 | Train Loss=0.0056 | Val Loss=0.0057 | LR=0.001000\n",
      "Epoch 4/60 | Train Loss=0.0055 | Val Loss=0.0042 | LR=0.001000\n",
      "Epoch 5/60 | Train Loss=0.0056 | Val Loss=0.0069 | LR=0.001000\n",
      "Epoch 6/60 | Train Loss=0.0052 | Val Loss=0.0040 | LR=0.001000\n",
      "Epoch 7/60 | Train Loss=0.0049 | Val Loss=0.0100 | LR=0.001000\n",
      "Epoch 8/60 | Train Loss=0.0048 | Val Loss=0.0127 | LR=0.001000\n",
      "Epoch 9/60 | Train Loss=0.0044 | Val Loss=0.0038 | LR=0.001000\n",
      "Epoch 10/60 | Train Loss=0.0048 | Val Loss=0.0054 | LR=0.001000\n",
      "Epoch 11/60 | Train Loss=0.0044 | Val Loss=0.0036 | LR=0.001000\n",
      "Epoch 12/60 | Train Loss=0.0044 | Val Loss=0.0094 | LR=0.001000\n",
      "Epoch 13/60 | Train Loss=0.0042 | Val Loss=0.0063 | LR=0.001000\n",
      "Epoch 14/60 | Train Loss=0.0042 | Val Loss=0.0126 | LR=0.001000\n",
      "Epoch 15/60 | Train Loss=0.0042 | Val Loss=0.0066 | LR=0.000500\n",
      "Epoch 16/60 | Train Loss=0.0040 | Val Loss=0.0102 | LR=0.000500\n",
      "Epoch 17/60 | Train Loss=0.0039 | Val Loss=0.0037 | LR=0.000500\n",
      "Epoch 18/60 | Train Loss=0.0039 | Val Loss=0.0048 | LR=0.000500\n",
      "Epoch 19/60 | Train Loss=0.0039 | Val Loss=0.0061 | LR=0.000250\n",
      "Epoch 20/60 | Train Loss=0.0036 | Val Loss=0.0033 | LR=0.000250\n",
      "Epoch 21/60 | Train Loss=0.0035 | Val Loss=0.0070 | LR=0.000250\n",
      "Epoch 22/60 | Train Loss=0.0037 | Val Loss=0.0059 | LR=0.000250\n",
      "Epoch 23/60 | Train Loss=0.0036 | Val Loss=0.0074 | LR=0.000250\n",
      "Epoch 24/60 | Train Loss=0.0036 | Val Loss=0.0029 | LR=0.000250\n",
      "Epoch 25/60 | Train Loss=0.0037 | Val Loss=0.0033 | LR=0.000250\n",
      "Epoch 26/60 | Train Loss=0.0036 | Val Loss=0.0078 | LR=0.000250\n",
      "Epoch 27/60 | Train Loss=0.0035 | Val Loss=0.0049 | LR=0.000250\n",
      "Epoch 28/60 | Train Loss=0.0036 | Val Loss=0.0038 | LR=0.000125\n",
      "Epoch 29/60 | Train Loss=0.0036 | Val Loss=0.0058 | LR=0.000125\n",
      "Epoch 30/60 | Train Loss=0.0034 | Val Loss=0.0056 | LR=0.000125\n",
      "Epoch 31/60 | Train Loss=0.0033 | Val Loss=0.0036 | LR=0.000125\n",
      "Epoch 32/60 | Train Loss=0.0035 | Val Loss=0.0047 | LR=0.000063\n",
      "Epoch 33/60 | Train Loss=0.0034 | Val Loss=0.0052 | LR=0.000063\n",
      "Epoch 34/60 | Train Loss=0.0034 | Val Loss=0.0056 | LR=0.000063\n",
      "Epoch 35/60 | Train Loss=0.0035 | Val Loss=0.0055 | LR=0.000063\n",
      "Epoch 36/60 | Train Loss=0.0033 | Val Loss=0.0052 | LR=0.000031\n",
      "Epoch 37/60 | Train Loss=0.0033 | Val Loss=0.0054 | LR=0.000031\n",
      "Epoch 38/60 | Train Loss=0.0034 | Val Loss=0.0053 | LR=0.000031\n",
      "Epoch 39/60 | Train Loss=0.0034 | Val Loss=0.0061 | LR=0.000031\n",
      "Epoch 40/60 | Train Loss=0.0034 | Val Loss=0.0053 | LR=0.000016\n",
      "Epoch 41/60 | Train Loss=0.0033 | Val Loss=0.0060 | LR=0.000016\n",
      "Epoch 42/60 | Train Loss=0.0034 | Val Loss=0.0061 | LR=0.000016\n",
      "Epoch 43/60 | Train Loss=0.0034 | Val Loss=0.0046 | LR=0.000016\n",
      "Epoch 44/60 | Train Loss=0.0034 | Val Loss=0.0050 | LR=0.000008\n",
      "Epoch 45/60 | Train Loss=0.0033 | Val Loss=0.0050 | LR=0.000008\n",
      "Epoch 46/60 | Train Loss=0.0035 | Val Loss=0.0053 | LR=0.000008\n",
      "Epoch 47/60 | Train Loss=0.0033 | Val Loss=0.0051 | LR=0.000008\n",
      "Epoch 48/60 | Train Loss=0.0033 | Val Loss=0.0057 | LR=0.000004\n",
      "Epoch 49/60 | Train Loss=0.0033 | Val Loss=0.0053 | LR=0.000004\n",
      "Epoch 50/60 | Train Loss=0.0034 | Val Loss=0.0054 | LR=0.000004\n",
      "Epoch 51/60 | Train Loss=0.0033 | Val Loss=0.0054 | LR=0.000004\n",
      "Epoch 52/60 | Train Loss=0.0034 | Val Loss=0.0053 | LR=0.000002\n",
      "Epoch 53/60 | Train Loss=0.0035 | Val Loss=0.0056 | LR=0.000002\n",
      "Epoch 54/60 | Train Loss=0.0033 | Val Loss=0.0053 | LR=0.000002\n",
      "Epoch 55/60 | Train Loss=0.0034 | Val Loss=0.0056 | LR=0.000002\n",
      "Epoch 56/60 | Train Loss=0.0034 | Val Loss=0.0055 | LR=0.000001\n",
      "Epoch 57/60 | Train Loss=0.0034 | Val Loss=0.0055 | LR=0.000001\n",
      "Epoch 58/60 | Train Loss=0.0033 | Val Loss=0.0055 | LR=0.000001\n",
      "Epoch 59/60 | Train Loss=0.0033 | Val Loss=0.0056 | LR=0.000001\n",
      "Epoch 60/60 | Train Loss=0.0033 | Val Loss=0.0056 | LR=0.000000\n",
      "\n",
      "=== METRICS ===\n",
      "MAE:  2143.0512\n",
      "RMSE: 2632.5313\n",
      "MAPE: 1.86%\n",
      "R²:   0.8064\n",
      "✅ Модель t=1 сохранена и предсказания добавлены\n",
      "Using device: cuda\n",
      "Epoch 1/60 | Train Loss=0.0467 | Val Loss=0.0124 | LR=0.001000\n",
      "Epoch 2/60 | Train Loss=0.0069 | Val Loss=0.0077 | LR=0.001000\n",
      "Epoch 3/60 | Train Loss=0.0062 | Val Loss=0.0100 | LR=0.001000\n",
      "Epoch 4/60 | Train Loss=0.0059 | Val Loss=0.0038 | LR=0.001000\n",
      "Epoch 5/60 | Train Loss=0.0058 | Val Loss=0.0260 | LR=0.001000\n",
      "Epoch 6/60 | Train Loss=0.0056 | Val Loss=0.0064 | LR=0.001000\n",
      "Epoch 7/60 | Train Loss=0.0054 | Val Loss=0.0028 | LR=0.001000\n",
      "Epoch 8/60 | Train Loss=0.0052 | Val Loss=0.0053 | LR=0.001000\n",
      "Epoch 9/60 | Train Loss=0.0053 | Val Loss=0.0046 | LR=0.001000\n",
      "Epoch 10/60 | Train Loss=0.0051 | Val Loss=0.0136 | LR=0.001000\n",
      "Epoch 11/60 | Train Loss=0.0048 | Val Loss=0.0064 | LR=0.000500\n",
      "Epoch 12/60 | Train Loss=0.0046 | Val Loss=0.0057 | LR=0.000500\n",
      "Epoch 13/60 | Train Loss=0.0045 | Val Loss=0.0064 | LR=0.000500\n",
      "Epoch 14/60 | Train Loss=0.0046 | Val Loss=0.0086 | LR=0.000500\n",
      "Epoch 15/60 | Train Loss=0.0045 | Val Loss=0.0034 | LR=0.000250\n",
      "Epoch 16/60 | Train Loss=0.0045 | Val Loss=0.0090 | LR=0.000250\n",
      "Epoch 17/60 | Train Loss=0.0043 | Val Loss=0.0084 | LR=0.000250\n",
      "Epoch 18/60 | Train Loss=0.0042 | Val Loss=0.0099 | LR=0.000250\n",
      "Epoch 19/60 | Train Loss=0.0043 | Val Loss=0.0048 | LR=0.000125\n",
      "Epoch 20/60 | Train Loss=0.0043 | Val Loss=0.0033 | LR=0.000125\n",
      "Epoch 21/60 | Train Loss=0.0042 | Val Loss=0.0041 | LR=0.000125\n",
      "Epoch 22/60 | Train Loss=0.0042 | Val Loss=0.0047 | LR=0.000125\n",
      "Epoch 23/60 | Train Loss=0.0042 | Val Loss=0.0046 | LR=0.000063\n",
      "Epoch 24/60 | Train Loss=0.0042 | Val Loss=0.0063 | LR=0.000063\n",
      "Epoch 25/60 | Train Loss=0.0041 | Val Loss=0.0042 | LR=0.000063\n",
      "Epoch 26/60 | Train Loss=0.0042 | Val Loss=0.0063 | LR=0.000063\n",
      "Epoch 27/60 | Train Loss=0.0041 | Val Loss=0.0067 | LR=0.000031\n",
      "Epoch 28/60 | Train Loss=0.0040 | Val Loss=0.0053 | LR=0.000031\n",
      "Epoch 29/60 | Train Loss=0.0040 | Val Loss=0.0065 | LR=0.000031\n",
      "Epoch 30/60 | Train Loss=0.0041 | Val Loss=0.0049 | LR=0.000031\n",
      "Epoch 31/60 | Train Loss=0.0041 | Val Loss=0.0060 | LR=0.000016\n",
      "Epoch 32/60 | Train Loss=0.0042 | Val Loss=0.0046 | LR=0.000016\n",
      "Epoch 33/60 | Train Loss=0.0041 | Val Loss=0.0054 | LR=0.000016\n",
      "Epoch 34/60 | Train Loss=0.0040 | Val Loss=0.0047 | LR=0.000016\n",
      "Epoch 35/60 | Train Loss=0.0040 | Val Loss=0.0049 | LR=0.000008\n",
      "Epoch 36/60 | Train Loss=0.0040 | Val Loss=0.0049 | LR=0.000008\n",
      "Epoch 37/60 | Train Loss=0.0040 | Val Loss=0.0060 | LR=0.000008\n",
      "Epoch 38/60 | Train Loss=0.0041 | Val Loss=0.0057 | LR=0.000008\n",
      "Epoch 39/60 | Train Loss=0.0041 | Val Loss=0.0049 | LR=0.000004\n",
      "Epoch 40/60 | Train Loss=0.0040 | Val Loss=0.0054 | LR=0.000004\n",
      "Epoch 41/60 | Train Loss=0.0041 | Val Loss=0.0056 | LR=0.000004\n",
      "Epoch 42/60 | Train Loss=0.0041 | Val Loss=0.0054 | LR=0.000004\n",
      "Epoch 43/60 | Train Loss=0.0041 | Val Loss=0.0050 | LR=0.000002\n",
      "Epoch 44/60 | Train Loss=0.0041 | Val Loss=0.0049 | LR=0.000002\n",
      "Epoch 45/60 | Train Loss=0.0040 | Val Loss=0.0047 | LR=0.000002\n",
      "Epoch 46/60 | Train Loss=0.0041 | Val Loss=0.0052 | LR=0.000002\n",
      "Epoch 47/60 | Train Loss=0.0041 | Val Loss=0.0051 | LR=0.000001\n",
      "Epoch 48/60 | Train Loss=0.0041 | Val Loss=0.0051 | LR=0.000001\n",
      "Epoch 49/60 | Train Loss=0.0041 | Val Loss=0.0052 | LR=0.000001\n",
      "Epoch 50/60 | Train Loss=0.0040 | Val Loss=0.0052 | LR=0.000001\n",
      "Epoch 51/60 | Train Loss=0.0041 | Val Loss=0.0050 | LR=0.000000\n",
      "Epoch 52/60 | Train Loss=0.0039 | Val Loss=0.0051 | LR=0.000000\n",
      "Epoch 53/60 | Train Loss=0.0040 | Val Loss=0.0051 | LR=0.000000\n",
      "Epoch 54/60 | Train Loss=0.0041 | Val Loss=0.0051 | LR=0.000000\n",
      "Epoch 55/60 | Train Loss=0.0041 | Val Loss=0.0050 | LR=0.000000\n",
      "Epoch 56/60 | Train Loss=0.0041 | Val Loss=0.0050 | LR=0.000000\n",
      "Epoch 57/60 | Train Loss=0.0040 | Val Loss=0.0050 | LR=0.000000\n",
      "Epoch 58/60 | Train Loss=0.0041 | Val Loss=0.0050 | LR=0.000000\n",
      "Epoch 59/60 | Train Loss=0.0041 | Val Loss=0.0050 | LR=0.000000\n",
      "Epoch 60/60 | Train Loss=0.0041 | Val Loss=0.0050 | LR=0.000000\n",
      "\n",
      "=== METRICS ===\n",
      "MAE:  2051.4365\n",
      "RMSE: 2439.1166\n",
      "MAPE: 1.79%\n",
      "R²:   0.8339\n",
      "✅ Модель t=3 сохранена и предсказания добавлены\n",
      "Using device: cuda\n",
      "Epoch 1/60 | Train Loss=0.0475 | Val Loss=0.0250 | LR=0.001000\n",
      "Epoch 2/60 | Train Loss=0.0088 | Val Loss=0.0272 | LR=0.001000\n",
      "Epoch 3/60 | Train Loss=0.0083 | Val Loss=0.0150 | LR=0.001000\n",
      "Epoch 4/60 | Train Loss=0.0076 | Val Loss=0.0067 | LR=0.001000\n",
      "Epoch 5/60 | Train Loss=0.0075 | Val Loss=0.0090 | LR=0.001000\n",
      "Epoch 6/60 | Train Loss=0.0075 | Val Loss=0.0059 | LR=0.001000\n",
      "Epoch 7/60 | Train Loss=0.0075 | Val Loss=0.0105 | LR=0.001000\n",
      "Epoch 8/60 | Train Loss=0.0066 | Val Loss=0.0134 | LR=0.001000\n",
      "Epoch 9/60 | Train Loss=0.0070 | Val Loss=0.0261 | LR=0.001000\n",
      "Epoch 10/60 | Train Loss=0.0066 | Val Loss=0.0137 | LR=0.000500\n",
      "Epoch 11/60 | Train Loss=0.0063 | Val Loss=0.0162 | LR=0.000500\n",
      "Epoch 12/60 | Train Loss=0.0061 | Val Loss=0.0064 | LR=0.000500\n",
      "Epoch 13/60 | Train Loss=0.0062 | Val Loss=0.0167 | LR=0.000500\n",
      "Epoch 14/60 | Train Loss=0.0061 | Val Loss=0.0079 | LR=0.000250\n",
      "Epoch 15/60 | Train Loss=0.0059 | Val Loss=0.0071 | LR=0.000250\n",
      "Epoch 16/60 | Train Loss=0.0059 | Val Loss=0.0105 | LR=0.000250\n",
      "Epoch 17/60 | Train Loss=0.0058 | Val Loss=0.0096 | LR=0.000250\n",
      "Epoch 18/60 | Train Loss=0.0059 | Val Loss=0.0122 | LR=0.000125\n",
      "Epoch 19/60 | Train Loss=0.0058 | Val Loss=0.0166 | LR=0.000125\n",
      "Epoch 20/60 | Train Loss=0.0057 | Val Loss=0.0089 | LR=0.000125\n",
      "Epoch 21/60 | Train Loss=0.0057 | Val Loss=0.0063 | LR=0.000125\n",
      "Epoch 22/60 | Train Loss=0.0056 | Val Loss=0.0061 | LR=0.000063\n",
      "Epoch 23/60 | Train Loss=0.0055 | Val Loss=0.0081 | LR=0.000063\n",
      "Epoch 24/60 | Train Loss=0.0056 | Val Loss=0.0103 | LR=0.000063\n",
      "Epoch 25/60 | Train Loss=0.0056 | Val Loss=0.0138 | LR=0.000063\n",
      "Epoch 26/60 | Train Loss=0.0056 | Val Loss=0.0112 | LR=0.000031\n",
      "Epoch 27/60 | Train Loss=0.0055 | Val Loss=0.0102 | LR=0.000031\n",
      "Epoch 28/60 | Train Loss=0.0055 | Val Loss=0.0107 | LR=0.000031\n",
      "Epoch 29/60 | Train Loss=0.0055 | Val Loss=0.0094 | LR=0.000031\n",
      "Epoch 30/60 | Train Loss=0.0055 | Val Loss=0.0105 | LR=0.000016\n",
      "Epoch 31/60 | Train Loss=0.0056 | Val Loss=0.0095 | LR=0.000016\n",
      "Epoch 32/60 | Train Loss=0.0056 | Val Loss=0.0108 | LR=0.000016\n",
      "Epoch 33/60 | Train Loss=0.0055 | Val Loss=0.0110 | LR=0.000016\n",
      "Epoch 34/60 | Train Loss=0.0056 | Val Loss=0.0094 | LR=0.000008\n",
      "Epoch 35/60 | Train Loss=0.0055 | Val Loss=0.0093 | LR=0.000008\n",
      "Epoch 36/60 | Train Loss=0.0055 | Val Loss=0.0100 | LR=0.000008\n",
      "Epoch 37/60 | Train Loss=0.0056 | Val Loss=0.0096 | LR=0.000008\n",
      "Epoch 38/60 | Train Loss=0.0055 | Val Loss=0.0096 | LR=0.000004\n",
      "Epoch 39/60 | Train Loss=0.0057 | Val Loss=0.0093 | LR=0.000004\n",
      "Epoch 40/60 | Train Loss=0.0055 | Val Loss=0.0095 | LR=0.000004\n",
      "Epoch 41/60 | Train Loss=0.0054 | Val Loss=0.0090 | LR=0.000004\n",
      "Epoch 42/60 | Train Loss=0.0057 | Val Loss=0.0095 | LR=0.000002\n",
      "Epoch 43/60 | Train Loss=0.0056 | Val Loss=0.0092 | LR=0.000002\n",
      "Epoch 44/60 | Train Loss=0.0055 | Val Loss=0.0094 | LR=0.000002\n",
      "Epoch 45/60 | Train Loss=0.0054 | Val Loss=0.0095 | LR=0.000002\n",
      "Epoch 46/60 | Train Loss=0.0056 | Val Loss=0.0092 | LR=0.000001\n",
      "Epoch 47/60 | Train Loss=0.0056 | Val Loss=0.0090 | LR=0.000001\n",
      "Epoch 48/60 | Train Loss=0.0056 | Val Loss=0.0093 | LR=0.000001\n",
      "Epoch 49/60 | Train Loss=0.0055 | Val Loss=0.0094 | LR=0.000001\n",
      "Epoch 50/60 | Train Loss=0.0055 | Val Loss=0.0096 | LR=0.000000\n",
      "Epoch 51/60 | Train Loss=0.0057 | Val Loss=0.0095 | LR=0.000000\n",
      "Epoch 52/60 | Train Loss=0.0055 | Val Loss=0.0095 | LR=0.000000\n",
      "Epoch 53/60 | Train Loss=0.0055 | Val Loss=0.0094 | LR=0.000000\n",
      "Epoch 54/60 | Train Loss=0.0056 | Val Loss=0.0095 | LR=0.000000\n",
      "Epoch 55/60 | Train Loss=0.0057 | Val Loss=0.0094 | LR=0.000000\n",
      "Epoch 56/60 | Train Loss=0.0055 | Val Loss=0.0095 | LR=0.000000\n",
      "Epoch 57/60 | Train Loss=0.0054 | Val Loss=0.0095 | LR=0.000000\n",
      "Epoch 58/60 | Train Loss=0.0056 | Val Loss=0.0095 | LR=0.000000\n",
      "Epoch 59/60 | Train Loss=0.0055 | Val Loss=0.0094 | LR=0.000000\n",
      "Epoch 60/60 | Train Loss=0.0056 | Val Loss=0.0094 | LR=0.000000\n",
      "\n",
      "=== METRICS ===\n",
      "MAE:  2747.4486\n",
      "RMSE: 3284.5608\n",
      "MAPE: 2.40%\n",
      "R²:   0.6987\n",
      "✅ Модель t=8 сохранена и предсказания добавлены\n",
      "✅ Все модели обучены и результаты сохранены в new_data.csv\n"
     ]
    }
   ],
   "source": [
    "create_models(df, path_dir= \"BTC-USD\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "a9df700d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr:last-of-type th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th>Price</th>\n",
       "      <th>Close</th>\n",
       "      <th>High</th>\n",
       "      <th>Low</th>\n",
       "      <th>Open</th>\n",
       "      <th>Volume</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Ticker</th>\n",
       "      <th>TSLA</th>\n",
       "      <th>TSLA</th>\n",
       "      <th>TSLA</th>\n",
       "      <th>TSLA</th>\n",
       "      <th>TSLA</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Datetime</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2023-11-13 14:30:00+00:00</th>\n",
       "      <td>219.985001</td>\n",
       "      <td>220.419998</td>\n",
       "      <td>211.610107</td>\n",
       "      <td>215.600006</td>\n",
       "      <td>38837399</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-11-13 15:30:00+00:00</th>\n",
       "      <td>223.529999</td>\n",
       "      <td>223.919998</td>\n",
       "      <td>219.369995</td>\n",
       "      <td>219.970001</td>\n",
       "      <td>26384434</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-11-13 16:30:00+00:00</th>\n",
       "      <td>224.130005</td>\n",
       "      <td>225.399994</td>\n",
       "      <td>222.710007</td>\n",
       "      <td>223.550003</td>\n",
       "      <td>20160326</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-11-13 17:30:00+00:00</th>\n",
       "      <td>222.121307</td>\n",
       "      <td>224.330002</td>\n",
       "      <td>221.570007</td>\n",
       "      <td>224.101196</td>\n",
       "      <td>14999487</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-11-13 18:30:00+00:00</th>\n",
       "      <td>224.860001</td>\n",
       "      <td>224.889999</td>\n",
       "      <td>221.770004</td>\n",
       "      <td>222.119995</td>\n",
       "      <td>13243605</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2025-11-11 14:30:00+00:00</th>\n",
       "      <td>435.266510</td>\n",
       "      <td>442.489990</td>\n",
       "      <td>434.820007</td>\n",
       "      <td>439.399994</td>\n",
       "      <td>13387275</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2025-11-11 15:30:00+00:00</th>\n",
       "      <td>433.369995</td>\n",
       "      <td>436.399994</td>\n",
       "      <td>432.739990</td>\n",
       "      <td>435.320007</td>\n",
       "      <td>8678369</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2025-11-11 16:30:00+00:00</th>\n",
       "      <td>433.920685</td>\n",
       "      <td>435.420013</td>\n",
       "      <td>432.359985</td>\n",
       "      <td>433.369995</td>\n",
       "      <td>6055282</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2025-11-11 17:30:00+00:00</th>\n",
       "      <td>435.830109</td>\n",
       "      <td>436.709991</td>\n",
       "      <td>433.230011</td>\n",
       "      <td>433.970001</td>\n",
       "      <td>12222320</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2025-11-11 18:30:00+00:00</th>\n",
       "      <td>436.720001</td>\n",
       "      <td>437.369995</td>\n",
       "      <td>434.082214</td>\n",
       "      <td>435.859985</td>\n",
       "      <td>3985198</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3485 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "Price                           Close        High         Low        Open  \\\n",
       "Ticker                           TSLA        TSLA        TSLA        TSLA   \n",
       "Datetime                                                                    \n",
       "2023-11-13 14:30:00+00:00  219.985001  220.419998  211.610107  215.600006   \n",
       "2023-11-13 15:30:00+00:00  223.529999  223.919998  219.369995  219.970001   \n",
       "2023-11-13 16:30:00+00:00  224.130005  225.399994  222.710007  223.550003   \n",
       "2023-11-13 17:30:00+00:00  222.121307  224.330002  221.570007  224.101196   \n",
       "2023-11-13 18:30:00+00:00  224.860001  224.889999  221.770004  222.119995   \n",
       "...                               ...         ...         ...         ...   \n",
       "2025-11-11 14:30:00+00:00  435.266510  442.489990  434.820007  439.399994   \n",
       "2025-11-11 15:30:00+00:00  433.369995  436.399994  432.739990  435.320007   \n",
       "2025-11-11 16:30:00+00:00  433.920685  435.420013  432.359985  433.369995   \n",
       "2025-11-11 17:30:00+00:00  435.830109  436.709991  433.230011  433.970001   \n",
       "2025-11-11 18:30:00+00:00  436.720001  437.369995  434.082214  435.859985   \n",
       "\n",
       "Price                        Volume  \n",
       "Ticker                         TSLA  \n",
       "Datetime                             \n",
       "2023-11-13 14:30:00+00:00  38837399  \n",
       "2023-11-13 15:30:00+00:00  26384434  \n",
       "2023-11-13 16:30:00+00:00  20160326  \n",
       "2023-11-13 17:30:00+00:00  14999487  \n",
       "2023-11-13 18:30:00+00:00  13243605  \n",
       "...                             ...  \n",
       "2025-11-11 14:30:00+00:00  13387275  \n",
       "2025-11-11 15:30:00+00:00   8678369  \n",
       "2025-11-11 16:30:00+00:00   6055282  \n",
       "2025-11-11 17:30:00+00:00  12222320  \n",
       "2025-11-11 18:30:00+00:00   3985198  \n",
       "\n",
       "[3485 rows x 5 columns]"
      ]
     },
     "execution_count": 136,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bdfc282",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1bc6379",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Начало обучения моделей для разных горизонтов предсказания...\n",
      "\n",
      "=== Обучение модели для предсказания на 1 час(ов) ===\n",
      "Ошибка при обучении модели для 1 часа(ов): Found array with 0 sample(s) (shape=(0, 1)) while a minimum of 1 is required by StandardScaler.\n",
      "\n",
      "=== Обучение модели для предсказания на 3 час(ов) ===\n",
      "Ошибка при обучении модели для 3 часа(ов): Found array with 0 sample(s) (shape=(0, 1)) while a minimum of 1 is required by StandardScaler.\n",
      "\n",
      "=== Обучение модели для предсказания на 9 час(ов) ===\n",
      "Ошибка при обучении модели для 9 часа(ов): Found array with 0 sample(s) (shape=(0, 1)) while a minimum of 1 is required by StandardScaler.\n",
      "\n",
      "DataFrame с предсказаниями сохранен: saved_models\\predictions_results_20251111_2105.csv\n"
     ]
    }
   ],
   "source": [
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
